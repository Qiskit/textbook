{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "formulas": {
     "_feature-map-eq": {
      "meaning": "A function that maps the input set to the Hilbert space."
     },
     "_kernel-function": {
      "meaning": "The kernel is a function of two data points that is a representation of the similarity between them."
     },
     "_state": {
      "meaning": "The state is a function of both the data point and the parameters, equivalent to the feature processing applied before the parameterized quantum circuit."
     }
    },
    "gloss": {
     "chair": {
      "text": "A chair is a piece of furniture, made for sitting on. <a href='https://en.wikipedia.org/wiki/Chair'>Read more</a>.",
      "title": "Chair"
     },
     "feature-map": {
      "text": "A function that maps the input set to features in the quantum Hilbert space.",
      "title": "Feature map"
     },
     "hilbert-space": {
      "text": "Hilbert space is what you get when you generalize the 3D space we're used to (called Euclidean space) to as many dimensions as you want. It’s named after David Hilbert. <a href='https://en.wikipedia.org/wiki/Hilbert_space'>Read more</a>.",
      "title": "Hilbert space"
     },
     "input-set": {
      "text": "A collection of data points that the the quantum model will try to learn about.",
      "title": "Input set"
     },
     "quantum-advantage": {
      "text": "“Quantum advantage” is where it will make economic sense to solve a problem using a quantum computer over a conventional computer.",
      "title": "Quantum advantage"
     }
    }
   },
   "source": [
    "# Supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs. It infers a function from labeled training data consisting of a set of training examples, and its performance is calculated using a set of testing examples.\n",
    "\n",
    "![](images/supervised/supervised-learning.png)\n",
    "\n",
    "We can separate supervised learning into two types of problems: **classification** and **regression**.\n",
    "- **Classification** asks us to assign data into specific categories. E.g.: given a set of labeled images of [chairs](gloss:chair) or tables, try to identify new photos of chairs or tables. \n",
    "- **Regression** asks us to understand the relationship between dependent and independent variables. It's commonly used to make predictions, e.g. given a series of historical stock prices, predict the future stock price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The focus of much recent research in near term quantum supervised learning has been in classification, and with two methods in particular:\n",
    "\n",
    "## Quantum variational classification\n",
    "\n",
    "![](images/supervised/vqc-circuit.svg)\n",
    "\n",
    "Given an [input set](gloss:input-set), $\\mathcal{X}$, and quantum [Hilbert space](gloss:hilbert-space), $\\mathcal{H}$, we encode data points $\\vec{x}_i \\in \\mathcal{X}$ into quantum states using the quantum [feature map](gloss:feature-map), i.e. $ \\class{_feature-map-eq}{U_\\Phi ∶ \\mathcal{X} \\rightarrow \\mathcal{H}}$, then process this state with a parameterized quantum circuit $W(\\theta)$. The resultant states become $ \\class{_state}{|\\Psi(x_i,\\theta)\\rangle = W(\\theta)| \\Phi(\\vec{x}_i)\\rangle}$ where parameters are estimated by training to match the target states $|y_i\\rangle $ that represent the $y_i$ labels of the training points.\n",
    "  \n",
    "This is covered in the [next page](./variational-classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum kernel estimation\n",
    "\n",
    "![](images/supervised/qke-circuit.svg)\n",
    "\n",
    "Given an input set, $\\mathcal{X}$, and quantum Hilbert space, $\\mathcal{H}$, data points $\\vec{x}_i \\in \\mathcal{X}$ are encoded into a quantum state by means of the quantum feature map, i.e. $U_\\Phi ∶ \\mathcal{X} \\rightarrow \\mathcal{H}$. The inner product of two quantum encoded quantum states define a kernel:\n",
    "\n",
    "$$ \\class{_kernel-function}{K(\\vec{x}_i,\\vec{x}_j)} \\equiv \\langle \\Phi(\\vec{x}_i) | \\Phi(\\vec{x}_j)\\rangle_{\\mathcal{H}}$$\n",
    "\n",
    "which is analogous to a kernel in classical machine learning.\n",
    "  \n",
    "This is covered in the [Quantum kernel estimation page](./quantum-feature-maps-kernels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both methods require a way to encode the data into a quantum state. There are several strategies to define the quantum feature map, or encoding, as discussed in a previous [section](./data-encoding). It is a key step in the success of the classification task, and to eventually obtain any [quantum advantage](gloss:quantum-advantage), we need the feature map to be classically intractable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1.  Maria Schuld and Francesco Petruccione, *Supervised Learning with Quantum Computers*, Springer 2018, [doi:10.1007/978-3-319-96424-9](https://www.springer.com/gp/book/9783319964232)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
